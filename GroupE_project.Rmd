---
title: "CHECK THE DATASETS, WE HAVE TO USE THE UNBALANCED ONE"
author: "A. Gottardi, E. Corrolezzis, A. Minutolo, L.F. Palacios Flores"
output:
  pdf_document: default
  toc: true
  html_document: null
  word_document: default
editor_options:
  markdown: null
  wrap: 72
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(patchwork); library(GGally); library(ggplot2); library(car); library(mgcv); library(skimr); library(viridis)
library(psych); library(gridExtra); library(dplyr); library(MASS)
```

```{r, include=FALSE}
current_path <- getwd()
datasets_dir <- file.path(current_path, "datasets")
load(paste(datasets_dir, "train_reduced.RData", sep = "/"))
load(paste(datasets_dir, "unbalanced_train.RData", sep = "/"))
load(paste(datasets_dir, "unbalanced_test.RData", sep = "/"))
```


# "Doubt the data until the data leave no room for doubt." - Henri Poincaré

# Problem statement
The dataset contains the data of the clients of an Insurance company that has provided Health Insurance. 
Our goal is to analyze the relationship between the features and the probability of the customers buying a vehicle insurance.
Now, in order to predict whether the customer would be interested in Vehicle insurance, we have information about demographics (gender, age, region code type), Vehicles (Vehicle Age, Damage), Policy ins(Premium, sourcing channel) etc.

Our client is an Insurance company that has provided Health Insurance to its customers. Now they need the help in building a model to predict whether the policyholders (customers) from the past year will also be interested in Vehicle Insurance provided by the company.

An insurance policy is an arrangement by which a company undertakes to provide a guarantee of compensation for specified loss, damage, illness, or death in return for the payment of a specified premium. A premium is a sum of money that the customer needs to pay regularly to an insurance company for this guarantee.

Building a model to predict whether a customer would be interested in Vehicle Insurance is extremely helpful for the company because it can then accordingly plan its communication strategy to reach out to those customers and optimize its business model and revenue.

# Data

We had three datasets to analyze 'train.csv', 'test.csv' and 'sample.csv'. Among these datasets we only analyzed the first one. The 'test.csv' dataset lacked the 'Response' variable and the 'sample.csv' file contained observations of this variable but one for one category, making them unusable.

Our dataset is composed of the following variables:

| Variable            | Definition                                                                                       | Type   |
|---------------------|--------------------------------------------------------------------------------------------------|--------|
| id                  | Unique ID for the customer                                                                       | Numeric|
| Gender              | Gender of the customer                                                                           | Categorical|
| Age                 | Age of the customer                                                                              | Numeric|
| Driving_License     | 0 : Customer does not have DL, 1 : Customer already has DL                                       | Binary |
| Region_Code         | Unique code for the region of the customer                                                       | Categorical|
| Previously_Insured  | 1 : Customer already has Vehicle Insurance, 0 : Customer doesn't have Vehicle Insurance         | Binary |
| Vehicle_Age         | Age of the Vehicle                                                                               | Categorical|
| Vehicle_Damage      | 1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past. | Binary |
| Annual_Premium      | The amount customer needs to pay as premium in the year                                           | Numeric|
| Policy_Sales_Channel| Anonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc. | Categorical|
| Vintage             | Number of Days, Customer has been associated with the company                                     | Numeric|
| Response            | 1 : Customer is interested, 0 : Customer is not interested                                       | Binary |

The first step is trying to get some insights about the dataset by plotting and analyzing the data. We present the barplots for the categorical variables and the density plots for the numerical ones.

The 'id' variable is just a discrete ordered variable with uniform distribution. Therefore, we just removed it from our analysis. 

## Exploratory Data Analysis

### 'Response' variable

The proportion for the categories of the response variable are the following:

```{r}
# Pie chart of Response variable with percentages of the total observations. 
# Calculate the percentages
response_counts <- table(train_reduced$Response)
response_props <- round(prop.table(response_counts) * 100, 2)

# Create a data frame for the pie chart
pie_data <- data.frame(
  Response = factor(names(response_counts), labels = c("No", "Yes")),
  Count = as.numeric(response_counts),
  Label = paste0(response_props, "%")
)

# Create the pie chart
p0 <- ggplot(pie_data, aes(x = "", y = Count, fill = Response)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  labs(x = "", y = "", fill = "Interest in Car Insurance") +
  theme_void() +
  theme(
    legend.position = "bottom",
    legend.text = element_text(size = 12),
    legend.title = element_text(size = 12), 
    text = element_text(size = 12)
  ) +
  geom_text(
    aes(y = Count / 2, label = Label),
    position = position_stack(vjust = 0.9),
    size = 8
  ) +
  scale_fill_discrete(labels = c("No", "Yes"))
p0
```

As we can see the dataset is unbalanced and the imbalance ratio is: 
```{r}
props <- table(train_reduced$Response)
IR<-as.numeric(props[1]/props[2])
sprintf("IR: %f", IR)
```
This degree of imbalance is considered to be weak with respect to the reference level of 10 for slight imbalance, thus we decided to not perform any procedure to correct the imbalance.

### Numerical variables

```{r, fig.width=15, fig.height=15}
p2 <- ggpairs(train_reduced, 
              columns = c("Age", "Annual_Premium", "Vintage"),
              aes(color = Response),
              diag = list(discrete="barDiag", 
                          continuous = wrap("densityDiag", alpha=0.7)))
p2
```
The distribution of the Age variable with respect to the Response variable shows that the majority of the customers who are interested in car insurance are middle-aged (between 30 and 60 years old), which coincides with the age people are more likely to own a car. 
The customers not interested in acquiring a car insurance policy are mostly distributed among younger people and some middle-aged adults in their 50s. The ditribution is skewed to the right.

The plot for Annual Premium suggests that the costs of the car insurance policy is independent of the interest if the customers to buy the product. It has a highly right-skewed distribution, with most of the data concentrated on the lower end of the premium scale and a long tail extending to higher premium values. The lower tail shows a high values as a consequence of entry level health insurance policy as expected.

Since both Age and Annual Premium are skewed to the right, we considered to apply a logarithm transformation for both the variables.
```{r, fig.width=15, fig.height=15}
train_reduced$logAge <- log(train_reduced$Age)
train_reduced$logAnnual_Premium <- log(train_reduced$Annual_Premium)
p3 <- ggpairs(train_reduced, 
              columns = c("logAge", "logAnnual_Premium"),
              aes(color = Response),
              diag = list(discrete="barDiag", 
                continuous = wrap("densityDiag", alpha=0.7 )))
p3
```

The plot for Vintage shows a nearly uniform distribution, with a slight increase in frequency towards the middle range of the Vintage variable. It may not be significant in the explanation of the Response.

The variables show negligible linear correlation between them, which is clearly shown in the scatter plot and in the correlation coefficients.

### Categorical variables

```{r, fig.width=15, fig.height=9}
p9 <- ggplot(train_reduced, aes(x = Region_Code, fill = Response)) + 
  geom_bar(position = "dodge", color = "black") +
  labs(y = "Count", fill = "Response") +
  scale_x_discrete(breaks = function(x) x[seq(1, length(x), by = 10)]) +
  theme(
    text = element_text(size = 12),
    axis.text = element_text(size = 14)
  )


p14 <- ggplot(train_reduced, aes(x = Policy_Sales_Channel, fill = Response)) + 
  geom_bar(position = "dodge", color = "black") +
  labs(y = "Count", fill = "Response") +
  scale_x_discrete(breaks = function(x) x[seq(1, length(x), by = 20)]) +
  theme(
    text = element_text(size = 12),
    axis.text = element_text(size = 14)
  )
p_cat <- p9 + p14
p_cat##Should be clearer
```

Regarding the variable Region_Code, we can notice that the vast majority of the customers are from region 28. The customers from region 28 are also the ones who are most interested in car insurance. 
Almost half of the customers are distributed among regions 8, 28, 41, 46 accounting for ~47% of the total customers. Since this variable has a lot of labels with low frequency, we decided to consider only the major four ones mentioned above and an additional one with the remaining labels as a unique category.

Also in Policy_Sales_Channel, there are four categories more frequent than others: Channels 26, 124, 152 and 160 alone account for more than 80% of the customers. Channels 26 and 124 are the ones with the highest percentage of customers interested in the product. Only about 20% of the customers interested in the product are distributed in the rest of the channels of outreach. As we did for Region_Code, we grouped the remaining less frequent categories as one.
  
  
  After the grouping:
```{r}
p10 <- ggplot(train_reduced, aes(x = Region_Reduced, fill = Response)) + 
  geom_bar(position = "dodge", color = "black") +
  labs(y = "Count", fill = "Response") +
  theme(
    text = element_text(size = 12),
    axis.text = element_text(size = 14)
  ) + 
  guides(fill = FALSE)
p15 <- ggplot(train_reduced, aes(x = Channels_Reduced, fill = Response)) + 
  geom_bar(position = "dodge", color = "black") +
  labs(y = "Count", fill = "Response") +
  theme(
    text = element_text(size = 12),
    axis.text = element_text(size = 14)
  ) + 
  guides(fill = FALSE)
p10+p15
```

Gender...


```{r}
p7 <- ggplot(train_df, aes(x = Gender, fill = Response)) + 
  geom_bar(position = "fill", color = "black") +
  labs(y = "Percentage", fill = "Response") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(
    text = element_text(size = 12),
    axis.text = element_text(size = 14)
  ) +
  guides(fill = FALSE)

p7
```


The last categorical variable is ID, which we won't consider for models, since it is a simple identifier of the customers. Hence it doesn't give any more information about the Response.

# MODELS

After exploring the data, now we proceed with the fitting and assessment of different models for binary classification. For training and testing the models we performed a static train/test split with 70% of train set and 30% of test set.

Il nostro scopo è capire quali variabili utilizzare e come utilizzarle.
-nested models statico con assessment
-stepAIC() con assessment
-rifare tutto con log?? oppure ne facciamo 2 in parallelo

In order to understand which variables are more significant in the explanation of the response variable, we analyzed nested models with different combinations of selected explanatory variables.

  
## stepAIC

The first approach we used consists of using the function stepAIC() from the MASS package to find the best combination of predictors with respect to AIC. The stepAIC() function must be applied to the full model, which serves as the starting point for the variable selection process. We chose the 'both' direction, that considers both adding and removing variables from the model.


```{r}
str(unbalanced_train)
```


```{r}
# Drop columns Policy_Sales_Channel and Region_Code from unbalanced_train
unbalanced_train <- unbalanced_train[, !names(unbalanced_train) %in% c("Policy_Sales_Channel", "Region_Code")]

# Drop columns Policy_Sales_Channel and Region_Code from unbalanced_test
unbalanced_test <- unbalanced_test[, !names(unbalanced_test) %in% c("Policy_Sales_Channel", "Region_Code")]
```


```{r}
full_model <- glm(Response ~ Gender + log(Age) + Driving_License + Previously_Insured + 
    Vehicle_Age + Vehicle_Damage + log(Annual_Premium) + Vintage + 
    Channels_Reduced + Region_Reduced, data = unbalanced_train, family = binomial)
stepAIC(full_model, direction = 'both')
```
Performing the stepAIC function we can see that, as previously said, the variable Vintage is not useful for the model, since its almost uniform distribution. The stepAIC function stops when the ranking of models built by removing and adding one variable at a time is not better than the default model. Hence, this procedure doesn't allow us to obtain a parsimonious model based on the Occam's razor. Consequentially we also implemented a procedure to obtain a reduced model based on idea of the stepAIC.

This procedure builds a ranking of variables, similar to the one of the stepAIC, meaning creating models by removing one variable at a time and sorting the variables by AIC. After that, we built nested models by adding one variable at a time based on the ranking of variables mentioned before.  

---COEFFICIENTS???---

## Nested models
The first approach consists of adding variables one by one, starting from an empty model and proceeding until all the variables considered in the model.
##Comparison and model selection

```{r, echo=FALSE, collapse=TRUE}
library(mgcViz)
library(ROSE)
library(ggplot2)
library(mgcv)
library(dplyr)
library(skimr)
library(pROC)
library(caret)
library(purrr)
#*LOAD THE DATA-----------------------------------------------------------------
# Define the path to the datasets
current_path <- dirname(rstudioapi::getActiveDocumentContext()$path)
datasets_dir <- paste(current_path,"datasets", sep = "/")
datasets_dir
#*--------------------------------------------------------------------
#*FUNCTIONS 
#*--------------------------------------------------------------------

# * This function assumes that `Policy_Sales_Channel` and `Region_Code` have been removed from the data
ranking_nested_models <- function(train_data, test_data, use_model = "glm", use_log = TRUE, use_splines = FALSE) {
  if(use_model == "glm" && use_log == TRUE){
    numeric_variables <- c("I(log(Age))", "I(log(Annual_Premium))")
  } else if (use_model == "glm" && use_log == FALSE){
    numeric_variables <- c("Age", "Annual_Premium")
  } else if (use_model == "gam" && use_log == TRUE && use_splines == TRUE){
    numeric_variables <- c("s(I(log(Age)))", "s(I(log(Annual_Premium)))")
  } else if (use_model == "gam" && use_log == TRUE && use_splines == FALSE){
    numeric_variables <- c("I(log(Age))", "I(log(Annual_Premium))")
  } else if (use_model == "gam" && use_log == FALSE && use_splines == TRUE){
    numeric_variables <- c("s(Age)", "s(Annual_Premium)")
  } else if (use_model == "gam" && use_log == FALSE && use_splines == FALSE){
    numeric_variables <- c("Age", "Annual_Premium")
  }

  #*VARIABLES IMPORTANCE RANKING --------------------------------------------------

  # Sort variables by importance wrt AIC
  # We remove one variable at a time and by decreasing AIC we get the most important variables
  # i.e., the variables that when removed increase the AIC is important
  predictors <- colnames(train_data)
  predictors <- predictors[predictors != 'Response']
  ranking_variables_models <- list()
  sum_variables <- paste(predictors, collapse = " + ")

  for (predictor in predictors){
    if (predictor == "Age"){
      formula_string <- paste("Response ~", sum_variables ,"- Annual_Premium -", predictor, "+", numeric_variables[2])

    } else if (predictor == "Annual_Premium"){
      formula_string <- paste("Response ~", sum_variables ,"- Age -", predictor, "+", numeric_variables[1])
    } else {
      formula_string <- paste("Response ~", sum_variables ,"- Age - Annual_Premium -", predictor, "+", paste(numeric_variables, collapse = " + "))

    }
    model_formula <- as.formula(formula_string)

    if(use_model == "glm"){
      model <- glm(model_formula, data = train_data, family = binomial)
    } else if (use_model == "gam"){
      model <- gam(model_formula, data = train_data, family = binomial)
    }

    ranking_variables_models[[predictor]] <- model
  }

  # Compute AIC values
  ranking_variables_aic_values <- sapply(ranking_variables_models, AIC)

  # Sort variables by AIC values
  df_ranking_variables_aic <- data.frame(VariableRemoved = predictors, AIC = ranking_variables_aic_values)
  # Assuming df is your DataFrame
  df_sorted_ranking_variables_aic <- df_ranking_variables_aic[order(df_ranking_variables_aic$AIC, decreasing=TRUE), ]
  # df_sorted_ranking_variables_aic

  #* NESTED MODELS ----------------------------------------------------------------
  variables_order <- df_sorted_ranking_variables_aic$VariableRemoved
  # variables_order
  variables_nested <- c()
  nested_models <- list()

  for (variable in variables_order) {
    if (variable == "Age"){
      variables_nested <- c(variables_nested, numeric_variables[1])
    } else if (variable == "Annual_Premium"){
      variables_nested <- c(variables_nested, numeric_variables[2])
    } else {
      variables_nested <- c(variables_nested, variable)
    }
    formula_string <- paste("Response", "~", paste(variables_nested, collapse = " + "))
    print(formula_string)  
    model_formula <- as.formula(formula_string)
    if(use_model == "glm"){
      model <- glm(model_formula, data = train_data, family = binomial)
    } else if (use_model == "gam"){
      model <- gam(model_formula, data = train_data, family = binomial)
    }
    
    nested_models[[variable]] <- model
  }

  # Compute AIC values
  raking_nested_models_aic_values <- sapply(nested_models, AIC)
  df_ranking_nested_models_aic <- data.frame(Model_Name = variables_order, AIC = raking_nested_models_aic_values)
  # df_ranking_nested_models_aic

  # Sort variables by AIC values
  df_sorted_ranking_nested_models_aic <- df_ranking_nested_models_aic[order(df_ranking_nested_models_aic$AIC, decreasing=TRUE), ]
  # df_sorted_ranking_nested_models_aic

  # Print the order of the variables to compare 
  # variables_order

  # COMPUTE AUC AND ACCURACY FOR EACH MODEL -------------------------------------

  # Apply models_assessment function to each model using map
  results_list <- map(nested_models, ~models_assessment(.x, test_data))

  # Compute AUC values
  auc_values <- list()
  accuracy_values <- list()
  tpr_values <- list()
  fpr_values <- list()
  tnr_values <- list()
  fnr_values <- list()
  precision_values <- list()
  threshold_values <- list()

  for (i in 1:length(results_list)){
    auc_values <- c(auc_values, as.numeric(results_list[[i]][1]))
    accuracy_values <- c(accuracy_values, as.numeric(results_list[[i]][2]))
    tpr_values <- c(tpr_values, as.numeric(results_list[[i]][3]))
    fpr_values <- c(fpr_values, as.numeric(results_list[[i]][4]))
    tnr_values <- c(tnr_values, as.numeric(results_list[[i]][5]))
    fnr_values <- c(fnr_values, as.numeric(results_list[[i]][6]))
    precision_values <- c(precision_values, as.numeric(results_list[[i]][7]))
    threshold_values <- c(threshold_values, as.numeric(results_list[[i]][8]))
  }

  result_df <- data.frame(
    Model_Name = df_ranking_nested_models_aic$Model_Name, 
    AIC = df_ranking_nested_models_aic$AIC,
    AUC = unlist(auc_values),
    Accuracy = unlist(accuracy_values),
    TPR = unlist(tpr_values),
    FPR = unlist(fpr_values),
    TNR = unlist(tnr_values),
    FNR = unlist(fnr_values),
    Precision = unlist(precision_values),
    Threshold = unlist(threshold_values)
  )

  # Return ranking of variables, | dataframe
  # results | dataframe
  # and nested models | list
  return(list(Ranking_Variables = df_sorted_ranking_variables_aic, Results = result_df, Models = nested_models))

}


#*FUNCTION TO PERFORM THE MODEL ASSESSMENT -------------------------------------
models_assessment <- function(model, test_data, save_plots = FALSE, plot_auc_name = NULL, plot_cmatrix_name = NULL){
  # Predict probabilities
  probabilities <- predict(model, newdata = subset(test_data, select = -Response), type = "response")

  # Compute ROC curve
  roc_curve <- roc(test_data$Response, probabilities)
  
  # Calculate AUC
  auc_score <- auc(roc_curve)

  # Find optimal threshold using Youden's J statistic
  youdens_j <- coords(roc_curve, "best", best.method = "youden")
  optimal_threshold <- youdens_j$threshold

  # Save ROC curve plot if specified
  if(save_plots){
    # Open a PNG file to save the ROC curve
    png(paste0(current_path, "/../plots/", plot_auc_name, ".png"),
        width = 10, height = 10,
        units = "in", res = 300)

    # Plot the ROC curve using plot.roc from the pROC package
    plot.roc(roc_curve, col = "blue", main = "ROC Curve", lwd = 2)

    # Add a point for the best threshold
    points(youdens_j$specificity, youdens_j$sensitivity, pch = 19, col = "red")

    # Adding a legend or text to mark the point
    text(youdens_j$specificity, youdens_j$sensitivity, labels = paste("Threshold:", round(optimal_threshold, 2)), pos = 4)

    # Add labels and legend
    abline(h = 0, v = 1, lty = 2, col = "gray")
    legend("topright", legend = paste("AUC =", round(auc(roc_curve), 2)), col = "blue", lwd = 2)

    # Close the PNG file
    dev.off()
  }

  # Obtain predicted classes based on the optimal threshold
  predicted_classes <- ifelse(probabilities > optimal_threshold, "Yes", "No")

  # Create the confusion matrix
  conf_matrix <- table(Actual = test_data$Response, Predicted = predicted_classes)

  conf_matrix_prop <- prop.table(conf_matrix, margin = 1)

  if(save_plots){
    # Plot confusion matrix
    p <- ggplot(data = as.data.frame(conf_matrix_prop), 
                aes(x = Actual, y = Predicted, fill = Freq)) +
      geom_tile(color = "white") +
      geom_text(aes(label = scales::percent(Freq)), vjust = 1) +
      scale_fill_gradient(low = "white", high = "blue") +
      labs(x = "Predicted", y = "Actual", fill = "Proportion") +
      theme_minimal()

    # Save the plot
    ggsave(paste0(current_path, "/../plots/", plot_cmatrix_name, ".png"),
           plot = p,
           width = 10, height = 10, dpi = 300)
  }

  # Calculate accuracy
  accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)

  # Calculate true positive rate
  tpr <- conf_matrix[2, 2] / sum(conf_matrix[2, ])

  # Calculate false positive rate
  fpr <- conf_matrix[1, 2] / sum(conf_matrix[1, ])

  # Calculate true negative rate
  tnr <- conf_matrix[1, 1] / sum(conf_matrix[1, ])

  # Calculate false negative rate
  fnr <- conf_matrix[2, 1] / sum(conf_matrix[2, ])

  # Calculate precision
  precision <- conf_matrix[2, 2] / sum(conf_matrix[, 2])

  return(list(auc_score = auc_score, accuracy = accuracy,
              tpr = tpr, fpr = fpr, tnr = tnr, fnr = fnr,
              precision = precision, optimal_threshold = optimal_threshold))

}

#*--------------------------------------------------------------------
#*RUN THE MODEL

```


```{r}
(result <- ranking_nested_models(unbalanced_train, unbalanced_test, use_model = "glm", use_log = FALSE, use_splines = FALSE))
```
```{r}
summary(result$Models$Driving_License)
```
```{r}
summary(result$Models$Region_Reduced)
```

```{r}
Anova(result$Models$Region_Reduced, result$Models$Driving_License)
```


### Select the best models

### The best overall
---plots of the gcVIZ library---

#### Binned residuals, VIF, Anova
---for anova and vif we only need to compute that for the best model or the full model---

#### Coefficients

## RF
Due to our limited computational resources, we had to sample our dataset in order to fit a random forest model with 500 trees.

### Performances


# Final conclusions
(skim)We observe that there are not missing values and that the Response variable has an imbalance rate of 7.15 (put code) so we don't need to act to fix that.
